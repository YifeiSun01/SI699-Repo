{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","trips = pd.read_csv(\"psrc_trips.csv\")\n","trips['weight'] = np.sum(trips[['trip_adult_weight_2021', 'trip_respondent_weight_2021',\n","       'trip_weight_2017', 'trip_weight_2019', 'trip_weight_2017_2019',\n","       'trip_adult_weight_2017_2019']].fillna(0).values,axis=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTFg_G8-js0Y","executionInfo":{"status":"ok","timestamp":1710536545336,"user_tz":240,"elapsed":7462,"user":{"displayName":"Yangyang Wang","userId":"12380533665329489687"}},"outputId":"60af2ae3-9c67-42c2-b323-def30a526cc2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-d9ac6fb59f80>:3: DtypeWarning: Columns (5,8,25,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,52,68,69,73,75,76,79,86,87,88,89,90,91,92,93,94,95,96,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,130,131,132,133,134,135,136,137,138,139,140,142,154) have mixed types. Specify dtype option on import or set low_memory=False.\n","  trips = pd.read_csv(\"psrc_trips.csv\")\n","<ipython-input-1-d9ac6fb59f80>:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  x = data.groupby(\"person_dim_id\")[\"vehicle_count\",\"hhincome_broad\",\"car_share\",\"numadults\",\"numchildren\",\"age_category\",\"gender\",\"employment\",\"education\",\"license\"].first().reset_index()\n"]}]},{"cell_type":"code","source":["trips[\"depart_time\"] = pd.to_datetime(trips[\"depart_time_string\"].str.replace(\"Date: \",\"\")).dt.hour\n","trips[\"depart_time\"]\n","trips[\"21-5c\"] = ((trips[\"depart_time\"]>=21) | (trips[\"depart_time\"]<5)) & (trips['o_tract10']!=trips[\"d_tract10\"])\n","trips[\"5-13c\"] = ((trips[\"depart_time\"]>=5) & (trips[\"depart_time\"]<13)) & (trips['o_tract10']!=trips[\"d_tract10\"])\n","trips[\"13-21c\"] = ((trips[\"depart_time\"]>=13) & (trips[\"depart_time\"]<21)) & (trips['o_tract10']!=trips[\"d_tract10\"])\n","trips[\"21-5s\"] = ((trips[\"depart_time\"]>=21) | (trips[\"depart_time\"]<5)) & (trips['o_tract10']==trips[\"d_tract10\"])\n","trips[\"5-13s\"] = ((trips[\"depart_time\"]>=5) & (trips[\"depart_time\"]<13)) & (trips['o_tract10']==trips[\"d_tract10\"])\n","trips[\"13-21s\"] = ((trips[\"depart_time\"]>=13) & (trips[\"depart_time\"]<21)) & (trips['o_tract10']==trips[\"d_tract10\"])"],"metadata":{"id":"CguvreQR7Glq","executionInfo":{"status":"ok","timestamp":1710537563739,"user_tz":240,"elapsed":293,"user":{"displayName":"Yangyang Wang","userId":"12380533665329489687"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["data = trips[[\"person_dim_id\",\"vehicle_count\",\"hhincome_broad\",\"car_share\",\"numadults\",\"numchildren\",\"age_category\",\"gender\",\"employment\",\"education\",\"license\",\"o_tract10\", \"21-5c\",\"5-13c\", \"13-21c\", \"21-5s\", \"5-13s\", \"13-21s\",'weight']].dropna(subset=['o_tract10'])\n","data = data.fillna('Unknown').replace(\"Missing: Skip Logic\", \"Unknown\").replace(\"Prefer not to answer\", \"Unknown\").replace(\"Not listed here / prefer not to answer\", \"Unknown\")\n","x = data.groupby(\"person_dim_id\")[\"vehicle_count\",\"hhincome_broad\",\"car_share\",\"numadults\",\"numchildren\",\"age_category\",\"gender\",\"employment\",\"education\",\"license\",\"o_tract10\"].first().reset_index()\n","w = data.groupby(\"person_dim_id\")[\"weight\"].first().reset_index()\n","y = data.groupby(\"person_dim_id\")[\"21-5c\",\"5-13c\", \"13-21c\", \"21-5s\", \"5-13s\", \"13-21s\" ].sum().reset_index()\n","x.to_csv(\"x.csv\")\n","y.to_csv(\"y.csv\")\n","w.to_csv(\"w.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSpDMdIe7Ipo","executionInfo":{"status":"ok","timestamp":1710539365234,"user_tz":240,"elapsed":720,"user":{"displayName":"Yangyang Wang","userId":"12380533665329489687"}},"outputId":"db45aad5-534a-41db-fa34-5dcda6c0cbf0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-b279ecacfd2b>:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  x = data.groupby(\"person_dim_id\")[\"vehicle_count\",\"hhincome_broad\",\"car_share\",\"numadults\",\"numchildren\",\"age_category\",\"gender\",\"employment\",\"education\",\"license\",\"o_tract10\"].first().reset_index()\n","<ipython-input-17-b279ecacfd2b>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  y = data.groupby(\"person_dim_id\")[\"21-5c\",\"5-13c\", \"13-21c\", \"21-5s\", \"5-13s\", \"13-21s\" ].sum().reset_index()\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.neighbors import KernelDensity\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.cross_decomposition import PLSRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.linear_model import LinearRegression\n","\n","class FirstModel():\n","    def __init__(self):\n","        self.pls = PLSRegression(n_components=10)\n","        self.encoder = OneHotEncoder()\n","        self.linear = LinearRegression()\n","        self.rf = RandomForestRegressor()\n","        self.knn = KNeighborsRegressor()\n","\n","    def train(self, x, y, w):\n","      x,y,w = x.iloc[:,1:], y.iloc[:,1:].values, w.iloc[:,1:].values\n","      x = self.encoder.fit_transform(x.values).toarray()\n","      x, _ = self.pls.fit_transform(x, y)\n","      self.linear.fit(x,y,sample_weight = w.ravel())\n","      self.rf.fit(x,y,sample_weight = w.ravel())\n","\n","    def predict(self, features, mode):\n","      x = self.pls.transform(self.encoder.transform([features]).toarray())\n","      if mode == \"Random Forest\":\n","        return self.rf.predict(x)\n","      else:\n","        return self.linear.predict(x)\n","\n","model = FirstModel()\n","model.train(x,y,w)\n","model.predict(x.iloc[1,1:].values.tolist(),\"Random Forest\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70I8-sTjlTZ0","executionInfo":{"status":"ok","timestamp":1710379486124,"user_tz":240,"elapsed":9703,"user":{"displayName":"Yangyang Wang","userId":"12380533665329489687"}},"outputId":"c1fabe26-d11f-4db8-fb94-3b88cc4751ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-9bd98988efc2>:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  self.rf.fit(x,y,sample_weight = w.ravel())\n"]},{"output_type":"execute_result","data":{"text/plain":["array([3.38358354])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from joblib import dump\n","dump(model, 'first_model.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMGaWHbUrNLv","executionInfo":{"status":"ok","timestamp":1710380896060,"user_tz":240,"elapsed":341,"user":{"displayName":"Yangyang Wang","userId":"12380533665329489687"}},"outputId":"5516c703-478a-4322-c572-5af93cd438c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['first_model.joblib']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yyOJorSykqeL"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","# Create a StandardScaler object\n","scaler = StandardScaler()\n","\n","first_phase = pd.read_csv(\"first_phase.csv\", index_col=0)\n","cluster = pd.read_csv(\"spectral_clustering_result.csv\", index_col=0)\n","cluster['final_home_tract10'] = cluster['Census Tract']\n","data = first_phase.merge(cluster, on=\"final_home_tract10\")\n","x_variable = ['vehicle_count',\n","       'hhincome_broad', 'car_share', 'numadults', 'numchildren',\n","       'age_category', 'gender', 'employment', 'education', 'license']\n","x = pd.DataFrame(scaler.fit_transform(data[x_variable]), columns=x_variable)\n","y = data[['trip_id']]\n","weight = data[['weight','Cluster']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xh_9s5dxCB7S"},"outputs":[],"source":["sample_weights_list = []\n","aug_factor = 10\n","for value in np.unique(weight['Cluster'].values):\n","  result = weight.apply(lambda row: row['weight'] * 10 if row['Cluster'] == value else row['weight'], axis=1)\n","  sample_weights_list.append(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n3QDljcZknnB","outputId":"9850ca9f-8a00-43c9-c49c-0ad4a9b053cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n","<ipython-input-3-8db40055f3df>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(X, y, sample_weight=weights)\n"]},{"data":{"text/plain":["<__main__.WeightedRegressor at 0x7ab4b619dc30>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["class WeightedRegressor:\n","    def __init__(self, regressor):\n","        self.regressor = regressor\n","        self.models = []\n","\n","    def fit(self, X, y, sample_weights_list):\n","        self.models = []\n","        for weights in sample_weights_list:\n","            model = self.regressor.__class__()  # Create a new instance of the regressor\n","            model.fit(X, y, sample_weight=weights)\n","            self.models.append(model)\n","        return self\n","\n","    def predict(self, X):\n","        y_preds = [model.predict(X) for model in self.models]\n","        return y_preds\n","\n","# Example usage:\n","from sklearn.ensemble import RandomForestRegressor\n","\n","\n","\n","# Initialize WeightedRegressor with a RandomForestRegressor\n","weighted_rf_regressor = WeightedRegressor(RandomForestRegressor())\n","\n","# Train the models with different weightings\n","weighted_rf_regressor.fit(x, y, sample_weights_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTayQ3VEkqj1","outputId":"bbe50645-9236-4a2c-ba32-1fdf0dbd44e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting shap\n","  Downloading shap-0.44.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/535.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/535.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.7/535.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n","Collecting slicer==0.0.7 (from shap)\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.44.1 slicer-0.0.7\n"]},{"name":"stderr","output_type":"stream","text":[" 64%|=============       | 6585/10267 [08:47<04:54]       "]}],"source":["!pip install shap\n","import numpy as np\n","import shap\n","\n","def compute_feature_importance(models, X_train, method='shap'):\n","    feature_importance = {}\n","    for i, model in enumerate(models):\n","        if method == 'shap':\n","            explainer = shap.Explainer(model, X_train)\n","            shap_values = explainer.shap_values(X_train)\n","            feature_importance[f'Model_{i+1}'] = np.abs(np.mean(shap_values, axis=0))\n","    return feature_importance\n","\n","# Compute feature importance across all models\n","all_feature_importance = compute_feature_importance(weighted_rf_regressor.models, x, method='shap')\n","\n","# Aggregate feature importance across all models\n","aggregate_feature_importance = {}\n","for model_feature_importance in all_feature_importance.values():\n","    for feature, importance in enumerate(model_feature_importance):\n","        if feature not in aggregate_feature_importance:\n","            aggregate_feature_importance[feature] = importance\n","        else:\n","            aggregate_feature_importance[feature] += importance\n","\n","# Normalize aggregated feature importance\n","total_sum = sum(aggregate_feature_importance.values())\n","normalized_feature_importance = {feature: importance / total_sum for feature, importance in aggregate_feature_importance.items()}\n","\n","# Sort by importance\n","sorted_feature_importance = dict(sorted(normalized_feature_importance.items(), key=lambda item: item[1], reverse=True))\n","\n","# Print or visualize sorted feature importance\n","print(\"Feature Importance:\")\n","for feature, importance in sorted_feature_importance.items():\n","    print(f\"Feature {feature+1}: Importance = {importance:.4f}\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOW6pTN+H32Rz/NYAtD7tG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}